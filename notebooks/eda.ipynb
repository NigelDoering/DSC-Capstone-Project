{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from IPython.display import Image, display\n",
    "os.chdir('..')\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/data-params.json') as fh:\n",
    "    data_cfg = json.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 'moderacy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_cfg['output_data_path'], 'data.csv')).drop(columns=['Unnamed: 0'])\n",
    "def remove_hashtags_and_ats(x):\n",
    "    return x.replace('#', '').replace('@', '')\n",
    "df['text'] = df['text'].apply(remove_hashtags_and_ats)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[dim].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# political_right use min_df = .00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', max_df=0.3, min_df=0.00001)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "clf = MultinomialNB(fit_prior=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', count_vect),\n",
    "                     ('tfidf', tfidf_transformer),\n",
    "                     ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(text_clf, df['text'], df[dim], cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df[dim], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(y_pred - y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(df['text'], df[dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', max_df=0.3, min_df=0.01)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "reg = Ridge(alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reg = Pipeline([('vect', count_vect),\n",
    "                     ('tfidf', tfidf_transformer),\n",
    "                     ('reg', reg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(text_reg, df['text'], df[dim], cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in user tweets\n",
    "tweets = {}\n",
    "for tweet_id in data_cfg['tweet_ids']:\n",
    "    path = os.path.join(data_cfg['output_user_data_path'], 'tweet_{}.csv'.format(tweet_id))\n",
    "    tweet = pickle.load(open(path, 'rb'))\n",
    "    tweets[tweet_id] = tweet\n",
    "    for key, value in tweets.items():\n",
    "        for user_id in list(value['user_ids'].keys()):\n",
    "            value['user_ids'][user_id] = pd.read_csv(os.path.join(data_cfg['output_user_data_path'], 'user_{}_tweets.csv'.format(user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Going through all the users of all the tweets\n",
    "# for tweet_id in tweets.keys():\n",
    "#     user_ids = list(tweets[tweet_id]['user_ids'].keys())\n",
    "#     for user_id in user_ids:\n",
    "#         df = pd.read_csv(os.path.join(data_cfg['output_user_data_path'], 'user_{}_tweets.csv'.format(user_id)))\n",
    "#         def remove_hashtags_and_ats(x):\n",
    "#             return x.replace('#', '').replace('@', '')\n",
    "#         df['text'] = df['text'].apply(remove_hashtags_and_ats)\n",
    "#         if df.shape[0] != 0:\n",
    "#             print('user_id: {}'.format(user_id))\n",
    "#             print(text_clf.predict_proba(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet_id in data_cfg['tweet_ids']:\n",
    "    user_ids = list(tweets[tweet_id]['user_ids'].keys())\n",
    "    print('Tweet ID: {}'.format(tweet_id))\n",
    "    print(user_ids)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '1061497789'\n",
    "df = pd.read_csv(os.path.join(data_cfg['output_user_data_path'], 'user_{}_tweets.csv'.format(user_id)))\n",
    "def remove_hashtags_and_ats(x):\n",
    "    return x.replace('#', '').replace('@', '')\n",
    "df['text'] = df['text'].apply(remove_hashtags_and_ats)\n",
    "display(df['text'])\n",
    "if df.shape[0] != 0:\n",
    "    print('user_id: {}'.format(user_id))\n",
    "    print(text_clf.predict(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
